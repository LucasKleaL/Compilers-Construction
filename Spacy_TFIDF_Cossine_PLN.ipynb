{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy-TFIDF-Cossine-PLN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XqLDbMbB5Qsc"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import requests\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data acquisition from web page url\n",
        "url = \"https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html\"\n",
        "data = requests.get(url)\n",
        "\n",
        "# loading the page content into soup\n",
        "soup = BeautifulSoup(data.content, \"html.parser\")\n",
        "\n",
        "# removing the html, style and script tags\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()\n",
        "\n",
        "# extrating only the text content \n",
        "text = soup.get_text()\n",
        "\n",
        "# break into lines and remove leading and trailing space on each\n",
        "lines = (line.strip() for line in text.splitlines())\n",
        "# break multi-headlines into a line each\n",
        "chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "# drop blank lines\n",
        "text = '\\n'.join(chunk for chunk in chunks if chunk)"
      ],
      "metadata": {
        "id": "WAeybmqy5YFx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading spacy nlp\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "pjrWvjD25bE5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spacyTokenizer(document):\n",
        "  tokens = nlp(document)\n",
        "  tokens = [token.lemma_ for token in tokens if (\n",
        "      token.is_stop == False and \n",
        "      token.is_punct == False and \n",
        "      token.lemma_.strip() != ''\n",
        "  )]\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "bYracvHo5fXm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the concatenated string into an array\n",
        "textSplit = text.splitlines()\n",
        "textContent = str(text).replace('\\n', ' ').replace(' ', '')"
      ],
      "metadata": {
        "id": "WugShnAi7KpF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instance of tf-idf Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# generate the tf-idf vectors for the textSplit\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(textSplit)\n",
        "\n",
        "# compute and print the cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "print(cosine_sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7opsUzmp5j0u",
        "outputId": "8f5f6e33-eefa-43d5-8503-87c0d4d62e69"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.30630504 0.07930533 ... 0.21496096 0.         0.        ]\n",
            " [0.30630504 1.         0.         ... 0.         0.         0.        ]\n",
            " [0.07930533 0.         1.         ... 0.368929   0.         0.        ]\n",
            " ...\n",
            " [0.21496096 0.         0.368929   ... 1.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         1.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         1.        ]]\n"
          ]
        }
      ]
    }
  ]
}